{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nfrom datasets import Audio\n\nminds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\nminds = minds.cast_column('audio', Audio(sampling_rate=16000))","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:01:14.460887Z","iopub.execute_input":"2024-10-30T07:01:14.461294Z","iopub.status.idle":"2024-10-30T07:02:46.541127Z","shell.execute_reply.started":"2024-10-30T07:01:14.461254Z","shell.execute_reply":"2024-10-30T07:02:46.539851Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"minds14.py:   0%|          | 0.00/5.83k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38f37d9b229a40d9a73249f64b7cccd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f51d0faeae0c4d689b4d8f9cc3f2baba"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"MInDS-14.zip:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a5e3eef0a16414db6bffc0ae55dfe61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a093a348da14887a63e59f28e9e0fc3"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Задача классификации**","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\n    \"audio-classification\",\n    model=\"anton-l/xtreme_s_xlsr_300m_minds14\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:03:22.924077Z","iopub.execute_input":"2024-10-30T07:03:22.924494Z","iopub.status.idle":"2024-10-30T07:03:53.961915Z","shell.execute_reply.started":"2024-10-30T07:03:22.924444Z","shell.execute_reply":"2024-10-30T07:03:53.960287Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d578773e4089489ebdce16eaaebdeffa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b70124003e2a4c8e9d0b93bb55ace450"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee907de00baf44c79589d3dea32f56a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef401351e1d043f8b1a274f32dd7ebf1"}},"metadata":{}}]},{"cell_type":"code","source":"classifier(minds[0]['audio']['array'])[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:08:16.365567Z","iopub.execute_input":"2024-10-30T07:08:16.366101Z","iopub.status.idle":"2024-10-30T07:08:19.413359Z","shell.execute_reply.started":"2024-10-30T07:08:16.366056Z","shell.execute_reply":"2024-10-30T07:08:19.411803Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'score': 0.9625310301780701, 'label': 'pay_bill'}"},"metadata":{}}]},{"cell_type":"code","source":"int2str = minds.features['intent_class'].int2str\nint2str(minds[0]['intent_class'])","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:16:46.233470Z","iopub.execute_input":"2024-10-30T07:16:46.233932Z","iopub.status.idle":"2024-10-30T07:16:46.248623Z","shell.execute_reply.started":"2024-10-30T07:16:46.233889Z","shell.execute_reply":"2024-10-30T07:16:46.247117Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'pay_bill'"},"metadata":{}}]},{"cell_type":"markdown","source":"**ASR**","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nasr = pipeline(\"automatic-speech-recognition\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:06:58.857642Z","iopub.execute_input":"2024-10-30T07:06:58.858738Z","iopub.status.idle":"2024-10-30T07:07:01.599147Z","shell.execute_reply.started":"2024-10-30T07:06:58.858662Z","shell.execute_reply":"2024-10-30T07:07:01.597767Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 22aad52 (https://huggingface.co/facebook/wav2vec2-base-960h).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e7f60688b842a8af898c23695eafab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"396699100a874cf8a689e0feb5b28172"}},"metadata":{}},{"name":"stderr","text":"Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2e8a52c4ec54153bd0b36efe169329b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f25ed84cf444142945c23761271bba9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a62639ded894a21814ae2cd6eca6501"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3edbed9bf68d4ad8b2d3e9d4be393be0"}},"metadata":{}}]},{"cell_type":"code","source":"asr(minds[0]['audio']['array'])","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:07:29.661014Z","iopub.execute_input":"2024-10-30T07:07:29.663507Z","iopub.status.idle":"2024-10-30T07:07:31.093541Z","shell.execute_reply.started":"2024-10-30T07:07:29.663337Z","shell.execute_reply":"2024-10-30T07:07:31.091775Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'text': 'I WOULD LIKE TO PAY MY ELECTRICITY BILL USING MY CAD CAN YOU PLEASE ASSIST'}"},"metadata":{}}]},{"cell_type":"code","source":"minds[0]['transcription']","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:17:34.245374Z","iopub.execute_input":"2024-10-30T07:17:34.245935Z","iopub.status.idle":"2024-10-30T07:17:34.261645Z","shell.execute_reply.started":"2024-10-30T07:17:34.245888Z","shell.execute_reply":"2024-10-30T07:17:34.260096Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'I would like to pay my electricity bill using my card can you please assist'"},"metadata":{}}]}]}